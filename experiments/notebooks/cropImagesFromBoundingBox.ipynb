{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cropImagesFromBoundingBox.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxFyQJhTJ4l-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "from pycocotools.coco import COCO\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import math\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import img_to_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQtAZVOLKJDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download caption annotation files 20GB files took around 20 mins to run\n",
        "\n",
        "annotation_folder = '/annotations/'\n",
        "if not os.path.exists(os.path.abspath('.') + annotation_folder):\n",
        "  annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
        "                                          cache_subdir=os.path.abspath('.'),\n",
        "                                          origin = 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip',\n",
        "                                          extract = True)\n",
        "  annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2017.json'\n",
        "  os.remove(annotation_zip)\n",
        "\n",
        "# Download image files\n",
        "image_folder = '/train2017/'\n",
        "if not os.path.exists(os.path.abspath('.') + image_folder):\n",
        "  image_zip = tf.keras.utils.get_file('train2017.zip',\n",
        "                                      cache_subdir=os.path.abspath('.'),\n",
        "                                      origin = 'http://images.cocodataset.org/zips/train2017.zip',\n",
        "                                      extract = True)\n",
        "  PATH = os.path.dirname(image_zip) + image_folder\n",
        "  os.remove(image_zip)\n",
        "else:\n",
        "  PATH = os.path.abspath('.') + image_folder\n",
        "\n",
        "  # Paths\n",
        "captions_path = '/content/annotations/captions_train2017.json'\n",
        "annotations_path = '/content/annotations/instances_train2017.json'\n",
        "images_path = '/content/train2017/'\n",
        "\n",
        "dir_content = os.listdir(images_path)\n",
        "\n",
        "# Load captions\n",
        "with open(captions_path) as json_file: \n",
        "    captions = json.load(json_file)\n",
        "\n",
        "# Load anotations\n",
        "with open(annotations_path) as json_file: \n",
        "    annotations = json.load(json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN0nz0i7Rfky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading dataframes\n",
        "df_images = pd.read_csv('Unique_images_with_Labels.csv',index_col = 0)\n",
        "df_train = pd.read_csv('captions_train.csv',names=['Images','Text'])\n",
        "df_test = pd.read_csv('captions_test.csv',names=['Images','Text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GiBmN9gTwUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_map = {'vehicle':3,'plane':5,'cat':17,'dog':18}\n",
        "def encoder(x):\n",
        "  return dict_map[x.lower()]\n",
        "\n",
        "df_images['Encoded_Labels'] = df_images['Label'].apply(lambda x: encoder(x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1egSsKFR9Uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_filenames = df_images['Images'].iloc[1:,:].to_list()\n",
        "encoded_labels = df_images['Encoded_Labels'].to_list()\n",
        "int_categories = [3,5,17,18]\n",
        "\n",
        "bbox = []\n",
        "for idx,names in enumerate(images_filenames):\n",
        "  name = names.split('.')[0]\n",
        "  image_id = re.sub('^0+','',name)\n",
        "  image_id = int(image_id)\n",
        "  category = encoded_labels[idx]\n",
        "  for i in annotations['annotations']:\n",
        "    if(i['image_id'] == image_id and i['category_id']==category):\n",
        "      bbox.append([image_id,i['bbox'],names,category])\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2lkt9NKyLjU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0da2bf2-9dcc-4e81-84e5-35e6e5ef8c42"
      },
      "source": [
        "os.chdir('/content/crop_images')\n",
        "\n",
        "for box in bbox:\n",
        "  img_name = box[2]\n",
        "  xmin,ymin,width,height = box[1][0],box[1][1],box[1][2],box[1][3]\n",
        "  xmax = xmin + width\n",
        "  ymax = ymin + height\n",
        "  area = (xmin,ymin,xmax,ymax)\n",
        "  img_path = os.path.join(images_path,img_name)\n",
        "  img = Image.open(img_path)\n",
        "  im =img.crop(area)\n",
        "  im = img_to_array(im)\n",
        "  cv2.imwrite(img_name,im)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVFHZJPw-_d0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_retained = []\n",
        "for i in os.listdir('/content/crop_images'):\n",
        "  images_retained.append(i)\n",
        "\n",
        "mask = df_images['Images'].apply(lambda x: x in images_retained)\n",
        "mask1 = df_train['Images_name'].apply(lambda x: x in images_retained)\n",
        "mask2 = df_test['Images_name'].apply(lambda x: x in images_retained)\n",
        "\n",
        "df_modified = df_images[mask]\n",
        "df_train_modified = df_train[mask1]\n",
        "df_test_modified = df_test[mask2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esz-MkxmCzPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_modified.to_csv('/content/crop_images/captions_train.csv',header=True)\n",
        "df_test_modified.to_csv('/content/crop_images/captions_test.csv',header=True)\n",
        "df_modified.to_csv('/content/crop_images/unique_images_with_labels.csv',header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2ZCAdvpF3mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "def zipdir(path, ziph):\n",
        "  for root, dirs, files in os.walk(path):\n",
        "    for file in files:\n",
        "      ziph.write(os.path.join(root, file))\n",
        "\n",
        "zipf = zipfile.ZipFile('/tmp/cropped_images.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "zipdir('/content/crop_images', zipf)\n",
        "zipf.close()\n",
        "\n",
        "files.download('/tmp/cropped_images.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}