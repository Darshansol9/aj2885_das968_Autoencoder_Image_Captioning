{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cleaning_CocoDataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtv6gihrDhXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import pickle\n",
        "import os\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from pycocotools.coco import COCO\n",
        "from tqdm import tqdm\n",
        "from shutil import copyfile\n",
        "import csv\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import zipfile\n",
        "import cv2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "felzLUPL1Qc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers import *\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_xvdG5_8MUA",
        "colab_type": "code",
        "outputId": "10558cb9-e3bc-41f1-d1d2-a9270417c99e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Download caption annotation files 20GB files took around 20 mins to run\n",
        "\n",
        "annotation_folder = '/annotations/'\n",
        "if not os.path.exists(os.path.abspath('.') + annotation_folder):\n",
        "  annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
        "                                          cache_subdir=os.path.abspath('.'),\n",
        "                                          origin = 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip',\n",
        "                                          extract = True)\n",
        "  annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2017.json'\n",
        "  os.remove(annotation_zip)\n",
        "\n",
        "# Download image files\n",
        "image_folder = '/train2014/'\n",
        "if not os.path.exists(os.path.abspath('.') + image_folder):\n",
        "  image_zip = tf.keras.utils.get_file('train2017.zip',\n",
        "                                      cache_subdir=os.path.abspath('.'),\n",
        "                                      origin = 'http://images.cocodataset.org/zips/train2017.zip',\n",
        "                                      extract = True)\n",
        "  PATH = os.path.dirname(image_zip) + image_folder\n",
        "  os.remove(image_zip)\n",
        "else:\n",
        "  PATH = os.path.abspath('.') + image_folder\n",
        "\n",
        "  # Paths\n",
        "captions_path = '/content/annotations/captions_train2017.json'\n",
        "annotations_path = '/content/annotations/instances_train2017.json'\n",
        "images_path = '/content/train2017/'\n",
        "\n",
        "dir_content = os.listdir(images_path)\n",
        "\n",
        "# Load captions\n",
        "with open(captions_path) as json_file: \n",
        "    captions = json.load(json_file)\n",
        "\n",
        "# Load anotations\n",
        "with open(annotations_path) as json_file: \n",
        "    annotations = json.load(json_file)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "252911616/252907541 [==============================] - 3s 0us/step\n",
            "Downloading data from http://images.cocodataset.org/zips/train2017.zip\n",
            "19336863744/19336861798 [==============================] - 310s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmSqSUbVKxhK",
        "colab_type": "code",
        "outputId": "2a7a9422-8ca2-4775-a0df-fd15d1efbf2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "#Map each category with the image_ids in a dictionary format\n",
        "#where keys are category number and values are image ids for that category.\n",
        "\n",
        "image_filenames = defaultdict(list)\n",
        "category_animal_id = [3,5,17,18]\n",
        "category_animal_name = ['vehicle','plane','cat','dog']\n",
        "\n",
        "category_id = category_animal_id\n",
        "category_name = category_animal_name\n",
        "\n",
        "category_map = dict()\n",
        "for i in range(len(category_id)):\n",
        "    category_map[category_id[i]] = category_name[i]\n",
        "\n",
        "for i in annotations['annotations']:\n",
        "    if i['category_id'] in category_id:\n",
        "        image_filenames[i['category_id']].append(i['image_id'])\n",
        "\n",
        "print('Completed')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJxxoTpdfkpi",
        "colab_type": "code",
        "outputId": "3dba415b-014d-4498-ac9d-895c747b28d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Task is to map image_ids with image_filenames\n",
        "\n",
        "plane = []\n",
        "plane.extend(image_filenames[5])\n",
        "f_plane = []\n",
        "for i in range(len(captions['images'])):\n",
        "  if(captions['images'][i]['id'] in plane ):\n",
        "    f_plane.append(captions['images'][i]['file_name'])\n",
        "\n",
        "print(len(f_plane))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mpOUTWzf6wd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plotCleanedImages(images_name,idx_to_start):\n",
        "  #Plotting few plane images to verify it's clean as expected\n",
        "  for img in images_name[idx_:320]:\n",
        "    img_ = cv2.imread(os.path.join(images_path,img))\n",
        "    plt.subplots(1,1)\n",
        "    plt.imshow(img_)\n",
        "    idx_to_start +=1\n",
        "\n",
        "#Plot plane images\n",
        "plotCleanedImages(f_planes,300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upEU-XBAg0_l",
        "colab_type": "code",
        "outputId": "8eb81a90-204c-428e-828d-83451cbe60b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#As images are pretty clean, we randomly select 1200 without repition images and made a dataframe from export to drive\n",
        "\n",
        "random_indexes = random.sample(range(len(f_plane)),1200)\n",
        "\n",
        "retain_images_plane = []\n",
        "for i in random_indexes:\n",
        "  retain_images_plane.append(f_plane[i])\n",
        "\n",
        "#Making dataframe to export\n",
        "\n",
        "df_plane = pd.DataFrame(retain_images_plane,columns=['Images'])\n",
        "df_plane['Label'] = ['plane'] * len(df_plane)\n",
        "df_plane.to_csv('Cleaned_Plane.csv',index=False)\n",
        "\n",
        "#Exporting\n",
        "!cp 'Cleaned_Plane.csv' \"drive/My Drive/\"\n",
        "\n",
        "#In this way we finished extracting cleaner images for plane category"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HojcwiUXDN1V",
        "colab_type": "code",
        "outputId": "8f8f3b28-30de-487b-82e5-38a2b7527569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Loading the pretrained model\n",
        "model = VGG16(weights='imagenet',include_top=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blbY3LjeE0Pu",
        "colab_type": "code",
        "outputId": "a933bf90-9a15-4a62-ba6c-54066159d541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "#Get images names for dog and cat categories using same tactic as plane\n",
        "\n",
        "dogcat = []\n",
        "dogcat.extend(image_filenames[17])\n",
        "dogcat.extend(image_filenames[18])\n",
        "f_dc = []\n",
        "for i in range(len(captions['images'])):\n",
        "  if(captions['images'][i]['id'] in dogcat ):\n",
        "    f_dc.append(captions['images'][i]['file_name'])\n",
        "\n",
        "#Performing for Cars\n",
        "cars = []\n",
        "cars.extend(image_filenames[3])\n",
        "f_cars = []\n",
        "for i in range(len(captions['images'])):\n",
        "  if(captions['images'][i]['id'] in cars ):\n",
        "    f_cars.append(captions['images'][i]['file_name'])\n",
        "\n",
        "count = 0\n",
        "retain_images = [] #store image to retain\n",
        "label_images = []  #store category of retained image\n",
        "\n",
        "#Kind of filter applied -- if pretrained model predicts anyone of these keywords as classes in an image retain that image else discard\n",
        "labels = ['cat','dog','husky','kitten','pug','puppies']\n",
        "retain_cars = ['streetcar','limousine','cab','passenger_car','car_mirror','jeep','car','minivan']\n",
        "\n",
        "#Check function perform many to one mapping i.e pug,puppies,husky will be tagged as dog\n",
        "\n",
        "def check(name):\n",
        "\n",
        "  #Checking for cars\n",
        "  if(name in retain_cars):\n",
        "    label_images.append('Vehicle')\n",
        "    return True\n",
        "\n",
        "  #Checking for cat and dog\n",
        "  for i in labels:\n",
        "    if(i in name):\n",
        "      if( i == 'cat' or i =='kitten'):\n",
        "        label_images.append('cat')\n",
        "      else:\n",
        "        label_images.append('dog')\n",
        "      return True\n",
        "\n",
        "  return False\n",
        "\n",
        "#This loop read the images present in f_dc lists and pass to VGG16 to make predictions\n",
        "#Predictions are then decoded and top 1 predicted classes is taken into account as it has highest probability\n",
        "#If the predicted class statisfies the check function the image name get append into retain_images list\n",
        "#We have monitored closely in batches of 100 how many images the model has captured perfectly\n",
        "\n",
        "def getPredictionsToStore(f_names,count):\n",
        "  for idx in range(len(f_names)):\n",
        "      img_path = os.path.join(images_path,f_names[idx])\n",
        "      img = cv2.imread(img_path)\n",
        "      img = cv2.resize(img, (224,224),cv2.IMREAD_GRAYSCALE,interpolation=cv2.INTER_CUBIC)\n",
        "      img_data = image.img_to_array(img)\n",
        "      img_data = np.expand_dims(img_data, axis=0)\n",
        "      img_data = preprocess_input(img_data)\n",
        "      predictions = model.predict(img_data)\n",
        "      classes = decode_predictions(predictions,top=1)\n",
        "      name,like = classes[0][0][1],classes[0][0][2] \n",
        "      if(check(name)):\n",
        "        retain_images.append(f_names[idx])\n",
        "      count +=1\n",
        "      if(count % 100 == 0):\n",
        "        print(f'Count is {count} and images captured is {len(retain_images)}')\n",
        "\n",
        "  print('Completed')\n",
        "\n",
        "print('Capturing for Cat_Dog Categories')\n",
        "getPredictionsToStore(f_dc,0)\n",
        "\n",
        "print('Capturing for Car categories')\n",
        "getPredictionsToStore(f_cars,0)\n",
        "\n",
        "#As seen in the output\n",
        "#The acceptance rate is 10-15% per 100 images, this help to process only clean data with actual label as cat/dog,rather than arbitary images seen in COCO dataset labeled as cat/dog"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count is 100 and images captured is 14\n",
            "Count is 200 and images captured is 27\n",
            "Count is 300 and images captured is 35\n",
            "Count is 400 and images captured is 51\n",
            "Count is 500 and images captured is 59\n",
            "Count is 600 and images captured is 75\n",
            "Count is 700 and images captured is 83\n",
            "Count is 800 and images captured is 94\n",
            "Count is 900 and images captured is 103\n",
            "Count is 1000 and images captured is 114\n",
            "Count is 1100 and images captured is 129\n",
            "Count is 1200 and images captured is 144\n",
            "Count is 1300 and images captured is 154\n",
            "Count is 1400 and images captured is 169\n",
            "Count is 1500 and images captured is 180\n",
            "Count is 1600 and images captured is 189\n",
            "Count is 1700 and images captured is 204\n",
            "Count is 1800 and images captured is 216\n",
            "Count is 1900 and images captured is 228\n",
            "Count is 2000 and images captured is 240\n",
            "Count is 2100 and images captured is 253\n",
            "Count is 2200 and images captured is 266\n",
            "Count is 2300 and images captured is 274\n",
            "Count is 2400 and images captured is 289\n",
            "Count is 2500 and images captured is 304\n",
            "Count is 2600 and images captured is 314\n",
            "Count is 2700 and images captured is 327\n",
            "Count is 2800 and images captured is 336\n",
            "Count is 2900 and images captured is 343\n",
            "Count is 3000 and images captured is 351\n",
            "Count is 3100 and images captured is 364\n",
            "Count is 3200 and images captured is 375\n",
            "Count is 3300 and images captured is 386\n",
            "Count is 3400 and images captured is 397\n",
            "Count is 3500 and images captured is 404\n",
            "Count is 3600 and images captured is 415\n",
            "Count is 3700 and images captured is 425\n",
            "Count is 3800 and images captured is 438\n",
            "Count is 3900 and images captured is 450\n",
            "Count is 4000 and images captured is 463\n",
            "Count is 4100 and images captured is 477\n",
            "Count is 4200 and images captured is 481\n",
            "Count is 4300 and images captured is 492\n",
            "Count is 4400 and images captured is 500\n",
            "Count is 4500 and images captured is 509\n",
            "Count is 4600 and images captured is 527\n",
            "Count is 4700 and images captured is 541\n",
            "Count is 4800 and images captured is 549\n",
            "Count is 4900 and images captured is 559\n",
            "Count is 5000 and images captured is 575\n",
            "Count is 5100 and images captured is 585\n",
            "Count is 5200 and images captured is 595\n",
            "Count is 5300 and images captured is 607\n",
            "Count is 5400 and images captured is 614\n",
            "Count is 5500 and images captured is 620\n",
            "Count is 5600 and images captured is 628\n",
            "Count is 5700 and images captured is 641\n",
            "Count is 5800 and images captured is 651\n",
            "Count is 5900 and images captured is 662\n",
            "Count is 6000 and images captured is 667\n",
            "Count is 6100 and images captured is 676\n",
            "Count is 6200 and images captured is 686\n",
            "Count is 6300 and images captured is 694\n",
            "Count is 6400 and images captured is 704\n",
            "Count is 6500 and images captured is 714\n",
            "Count is 6600 and images captured is 721\n",
            "Count is 6700 and images captured is 733\n",
            "Count is 6800 and images captured is 742\n",
            "Count is 6900 and images captured is 758\n",
            "Count is 7000 and images captured is 772\n",
            "Count is 7100 and images captured is 788\n",
            "Count is 7200 and images captured is 802\n",
            "Count is 7300 and images captured is 813\n",
            "Count is 7400 and images captured is 823\n",
            "Count is 7500 and images captured is 836\n",
            "Count is 7600 and images captured is 844\n",
            "Count is 7700 and images captured is 852\n",
            "Count is 7800 and images captured is 855\n",
            "Count is 7900 and images captured is 866\n",
            "Count is 8000 and images captured is 874\n",
            "Count is 8100 and images captured is 883\n",
            "Count is 8200 and images captured is 892\n",
            "Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNMHVW2PIeWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check the cleaned images and predicted category correctly by VGG16 for each categories\n",
        "plotCleanedImages(retain_images,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY6rNEFHIp1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert into dataframe and ready for export for all categories\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "df_dcc = pd.DataFrame(retain_images,columns=['Images'])\n",
        "df_dcc['Label'] = label_images\n",
        "\n",
        "#Combining all four categories dataframe and merging into one dataframe for export\n",
        "df_images = pd.concat([df_plane,df,df_dcc])\n",
        "df_images.to_csv('Cleaned_Images.csv',index=False)\n",
        "\n",
        "#Export Clean images to Gdrive\n",
        "!cp 'Cleaned_Images.csv' \"drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrsN6-yqpVQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#From merge dataFrame get the images label and images names\n",
        "\n",
        "#f_cars = df_images[df_images['Label'] == 'Vehicle']\n",
        "#f_cat = df_images[df_images['Label'] == 'cat']\n",
        "#f_dog = df_images[df_images['Label'] == 'dog']\n",
        "#f_plane = df_images[df_images['Label'] == 'plane']\n",
        "\n",
        "df_unique = pd.DataFrame()\n",
        "df_unique = df_images.drop_duplicates(keep=False)\n",
        "\n",
        "def getImage_Labels():\n",
        "\n",
        "  #Remove the duplicates in case in the dataframe to avoid mapping same images to multiple category\n",
        "  f_car = df_unique[df_unique['Label'] == 'Vehicle']['Images']\n",
        "  f_cat = df_unique[df_unique['Label'] == 'cat']['Images']\n",
        "  f_dog = df_unique[df_unique['Label'] == 'dog']['Images']\n",
        "  f_plane = df_unique[df_unique['Label'] == 'plane']['Images']\n",
        "\n",
        "  #Type cast to list\n",
        "  f_car = list(f_car)\n",
        "  f_cat = list(f_cat)\n",
        "  f_dog = list(f_dog)\n",
        "  f_plane = list(f_plane)\n",
        "\n",
        "  return f_car,f_cat,f_dog,f_plane\n",
        "\n",
        "f_car,f_cat,f_dog,f_plane = getImage_Labels()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AECQWKbtLTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This process is extracting from image name get their image id\n",
        "#This will be used to extract the captions for that image as the field used in annotations is 'image_id'\n",
        "\n",
        "car_ids =  []\n",
        "dog_ids = []\n",
        "plane_ids = []\n",
        "cat_ids = []\n",
        "dict_images = defaultdict(list)\n",
        "\n",
        "for i in range(len(captions['images'])):\n",
        "  file_name = captions['images'][i]['file_name']\n",
        "  if( file_name in f_car):\n",
        "    car_ids.append(captions['images'][i]['id'])\n",
        "  elif(file_name in f_cat):\n",
        "    cat_ids.append(captions['images'][i]['id'])\n",
        "  elif(file_name in f_dog):\n",
        "    dog_ids.append(captions['images'][i]['id'])\n",
        "  elif(file_name in f_plane):\n",
        "    plane_ids.append(captions['images'][i]['id'])\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnvwjvrOyhqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Re-initialzing the original image_filenames dict with image ids uniquely belonging to particular category\n",
        "\n",
        "category_vehicle_id = [3, 5]\n",
        "category_vehicle_name = ['car', 'plane']\n",
        "category_animal_id = [17, 18]\n",
        "category_animal_name = ['cat', 'dog']\n",
        "category_id = category_vehicle_id + category_animal_id\n",
        "category_name = category_vehicle_name + category_animal_name\n",
        "category_map = dict()\n",
        "\n",
        "for i in range(len(category_id)):\n",
        "    category_map[category_id[i]] = category_name[i]\n",
        "\n",
        "image_filenames_all = {3:car_ids,5:plane_ids,17:cat_ids,18:dog_ids}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK4CQrbe_Rg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_cat_file_counts = defaultdict(list)\n",
        "for i in tqdm(category_id):\n",
        "    for j in tqdm(image_filenames_all[i]):\n",
        "        count_cats = 0\n",
        "        for k in annotations['annotations']:\n",
        "            if k['image_id'] == j:\n",
        "                count_cats += 1\n",
        "        image_cat_file_counts[i].append([j, count_cats])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM4LkqkqzeYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing duplicates\n",
        "unique_dict = {}\n",
        "for k,v in image_cat_file_counts.items():\n",
        "    new=[]\n",
        "    for i in v:\n",
        "        new.append(tuple(i))\n",
        "    unique_dict[k] = list(set(new))\n",
        "\n",
        "# Saving images and captions to directory\n",
        "coco_caps = COCO(captions_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQEBEYIpEBMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filtering the image filenames\n",
        "\n",
        "filtered_filenames_train = defaultdict(list)\n",
        "filtered_filenames_test = defaultdict(list)\n",
        "\n",
        "for k, v in unique_dict.items():\n",
        "    v_sorted = sorted(v, key = (lambda x: x[1]))\n",
        "    for i in range(len(v_sorted)):\n",
        "        if i%5==0:            \n",
        "            filtered_filenames_test[k].append(v_sorted[i])\n",
        "        else:\n",
        "            filtered_filenames_train[k].append(v_sorted[i])\n",
        "\n",
        "#From the 2945 images we split into train and test by creating respective diretories\n",
        "\n",
        "for i in category_name:\n",
        "    os.makedirs('/content/train/'+i)\n",
        "    os.makedirs('/content/test/'+i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqXvVJScA2DT",
        "colab_type": "code",
        "outputId": "4be3298e-55b9-40c8-9f4f-ead6e99d1bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# WRITE TRAIN\n",
        "captions_train = []\n",
        "for k, v in filtered_filenames_train.items():\n",
        "    for file in tqdm(v):\n",
        "\n",
        "        # Save Image\n",
        "        dirname = category_map[k]\n",
        "        filename = str(file[0]).zfill(12)+'.jpg'\n",
        "        src = images_path + filename\n",
        "\n",
        "        dst = 'content'+'/train/'+dirname+'/'+filename\n",
        "        copyfile(src, dst)\n",
        "        \n",
        "        #extract captions\n",
        "        annIds = coco_caps.getAnnIds(imgIds=file[0])\n",
        "        anns = coco_caps.loadAnns(annIds)\n",
        "        \n",
        "        for i in range(len(anns)):\n",
        "            captions_train.append([filename+'#'+str(i), anns[i]['caption']])\n",
        "    \n",
        "with open('/content/train/captions_train.csv', \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(captions_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1045/1045 [00:01<00:00, 829.94it/s]\n",
            "100%|██████████| 603/603 [00:01<00:00, 407.27it/s]\n",
            "100%|██████████| 428/428 [00:01<00:00, 388.36it/s]\n",
            "100%|██████████| 294/294 [00:00<00:00, 353.99it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zug3vEhnE_dp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in os.listdir('/content/train'):\n",
        "  if( i == 'captions_train.csv'):\n",
        "    df_captions = pd.read_csv('/content/train/captions_train.csv',names=['Images','Labels'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlL2WB6gGZTT",
        "colab_type": "code",
        "outputId": "2d1681b5-a5d7-4135-c2a5-00e2864feaa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "df_captions.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Images</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000000423052.jpg#0</td>\n",
              "      <td>A sign and car on a city street.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000000423052.jpg#1</td>\n",
              "      <td>Store front on an old narrow city street with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000000423052.jpg#2</td>\n",
              "      <td>A sidewalk with a large sign that's been alter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000000423052.jpg#3</td>\n",
              "      <td>a vandalized parking sign that reads \"free con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000000423052.jpg#4</td>\n",
              "      <td>A sign points to a traffic cone above it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>000000407559.jpg#0</td>\n",
              "      <td>Scene of a building through the mirror of a ve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>000000407559.jpg#1</td>\n",
              "      <td>Rear view mirror of car with a sign reflected ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>000000407559.jpg#2</td>\n",
              "      <td>City lights shine while a car rear view mirror...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>000000407559.jpg#3</td>\n",
              "      <td>Someone checks a side mirror while in their car.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>000000407559.jpg#4</td>\n",
              "      <td>There are some colored lights hanging from str...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Images                                             Labels\n",
              "0  000000423052.jpg#0                   A sign and car on a city street.\n",
              "1  000000423052.jpg#1  Store front on an old narrow city street with ...\n",
              "2  000000423052.jpg#2  A sidewalk with a large sign that's been alter...\n",
              "3  000000423052.jpg#3  a vandalized parking sign that reads \"free con...\n",
              "4  000000423052.jpg#4          A sign points to a traffic cone above it.\n",
              "5  000000407559.jpg#0  Scene of a building through the mirror of a ve...\n",
              "6  000000407559.jpg#1  Rear view mirror of car with a sign reflected ...\n",
              "7  000000407559.jpg#2  City lights shine while a car rear view mirror...\n",
              "8  000000407559.jpg#3  Someone checks a side mirror while in their car. \n",
              "9  000000407559.jpg#4  There are some colored lights hanging from str..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzkArIx2F3gQ",
        "colab_type": "code",
        "outputId": "a33d1a72-15f3-463d-8ecd-35120ca87d67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# WRITE TEST\n",
        "captions_test = []\n",
        "for k, v in filtered_filenames_test.items():\n",
        "    for file in tqdm(v):\n",
        "        # Save Image\n",
        "        dirname = category_map[k]\n",
        "        filename = str(file[0]).zfill(12)+'.jpg'\n",
        "        src = images_path + filename\n",
        "        dst = '/content/test/'+dirname+'/'+filename\n",
        "        copyfile(src, dst)\n",
        "        #extract captions\n",
        "        annIds = coco_caps.getAnnIds(imgIds=file[0])\n",
        "        anns = coco_caps.loadAnns(annIds)\n",
        "        \n",
        "        for i in range(len(anns)):\n",
        "            captions_test.append([filename+'#'+str(i), anns[i]['caption']])\n",
        "\n",
        "with open('/content/test/captions_test.csv', \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(captions_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 262/262 [00:01<00:00, 243.09it/s]\n",
            "100%|██████████| 151/151 [00:00<00:00, 255.45it/s]\n",
            "100%|██████████| 107/107 [00:00<00:00, 1547.60it/s]\n",
            "100%|██████████| 74/74 [00:00<00:00, 1240.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8GTgZBkzn3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Exporting the captions for train and test to Gdrive along with a DataFrame which contains image_name and label it belonged to.\n",
        "df_unique.to_csv('Unique_images_with_Labels.csv',header=True)\n",
        "!cp 'Unique_images_with_Labels.csv' \"drive/My Drive/\"\n",
        "!cp '/content/test/captions_test.csv' \"drive/My Drive/\"\n",
        "!cp '/content/train/captions_train.csv' \"drive/My Drive/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM6X_Bc14KFK",
        "colab_type": "text"
      },
      "source": [
        "**Thank you**"
      ]
    }
  ]
}